{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I - Obtain and aggregate data from Quandl and Refinitive (EOD and ESG data respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add path for python to look into for modules installed using pip\n",
    "# Without this, only conda-installed modules are detected\n",
    "\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "\n",
    "import quandl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "quandl.ApiConfig.api_key = \"n2tNssPxEFC9-Ad79fo-\" # keep this private\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ticker/RIC codes from different stock exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ticker symbol data from https://www.eoddata.com were downloaded.\n",
    "* A function that gets the ticker symbols for each stock exchange was defined, *Get_Codes*. This was used to get data from Quandl.\n",
    "* Another function, *Add_Extension*, was defined that adds an appropriate extension to the *Get_Codes* output converting it into RIC code (see https://www.reuters.com/finance/stocks/lookup?searchType=any&search=%25RIC%25 for details). This was used to get ESG data from Refinitiv.\n",
    "* Lists containing tickers and RICs to get data from Quandl and Refinitiv respectively were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYSE_quandl: 3135\n",
      "NASDAQ_quandl: 3504\n",
      "ASE_quandl: 2266\n",
      "NYSE_rifinitiv: 3135\n",
      "NASDAQ_rifinitiv: 3504\n",
      "ASE_rifinitiv: 2266\n"
     ]
    }
   ],
   "source": [
    "def Get_Codes(stock_exchange):\n",
    "    \n",
    "    data = pd.read_csv('data/'+str(stock_exchange)+\".csv\", encoding='unicode_escape')\n",
    "    company_name = []\n",
    "\n",
    "    for i in data[\"Symbol\"]:\n",
    "    \n",
    "        company_name.append(i)\n",
    "\n",
    "    codes = np.asarray(company_name)\n",
    "    \n",
    "    return codes\n",
    "\n",
    "\n",
    "Get_Codes(\"NYSE\")\n",
    "\n",
    "Get_Codes(\"NASDAQ\")\n",
    "\n",
    "Get_Codes(\"ASE\")\n",
    "\n",
    "# We must add the codes at the end to make it compatible with Refinitiv data\n",
    "\n",
    "def Add_Extension(codes, ext):\n",
    "    \n",
    "    newcodes = []\n",
    "    \n",
    "    for i in codes:\n",
    "        \n",
    "        newcodes.append(str(i) + str(ext))\n",
    "        \n",
    "    new = np.asarray(newcodes)\n",
    "    \n",
    "    return new   \n",
    "\n",
    "Add_Extension(Get_Codes(\"NASDAQ\"), ext=\".O\")\n",
    "\n",
    "# We can now create a list of extensions to call the above function for each stock exchange:\n",
    "\n",
    "# list can be found at: \n",
    "# http://training.thomsonreuters.com/portal/docs/pdf/raymondjames/Thomson_One_Exchange_List.pdf\n",
    "\n",
    "# For the time being we have the 3 largest American Stock Exchanges:\n",
    "\n",
    "# - NYSE: .N\n",
    "# - NASDAQ: .O\n",
    "# - ASE: .A\n",
    "\n",
    "# Get Quandl data\n",
    "\n",
    "NYSE_quandl = list(Get_Codes(\"NYSE\"))\n",
    "NASDAQ_quandl = list(Get_Codes(\"NASDAQ\"))\n",
    "ASE_quandl = list(Get_Codes(\"ASE\"))\n",
    "\n",
    "# Get Refinitiv data\n",
    "\n",
    "NYSE_refinitiv = list(Add_Extension(Get_Codes(\"NYSE\"), ext=\".N\"))\n",
    "NASDAQ_refinitiv = list(Add_Extension(Get_Codes(\"NASDAQ\"), ext=\".O\"))\n",
    "ASE_refinitiv = list(Add_Extension(Get_Codes(\"ASE\"), ext=\".A\"))\n",
    "\n",
    "print('NYSE_quandl:', len(NYSE_quandl))\n",
    "print('NASDAQ_quandl:', len(NASDAQ_quandl))\n",
    "print('ASE_quandl:', len(ASE_quandl))\n",
    "\n",
    "print('NYSE_refinitiv:', len(NYSE_refinitiv))\n",
    "print('NASDAQ_refinitiv:', len(NASDAQ_refinitiv))\n",
    "print('ASE_refinitiv:', len(ASE_refinitiv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start/end dates\n",
    "\n",
    "start = '2010-10-15'\n",
    "end = '2018-10-15'\n",
    "\n",
    "oos_start = end\n",
    "oos_end = '2019-10-15'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinitiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Functions created by Refinitive to obtain their data were defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Refinitiv #####\n",
    "\n",
    "# The following values are populated for you by Data Science Accelerator. \n",
    "# They represent your demo-level access to the data.\n",
    "# Please don't share this with anyone\n",
    "\n",
    "RESOURCE_ENDPOINT = 'https://dsa-stg-edp-api.fr-nonprod.aws.thomsonreuters.com/data/environmental-social-governance/v1/views/scores-full'\n",
    "\n",
    "# RESOURCE_ENDPOINT = 'https://dsa-stg-edp-api.fr-nonprod.aws.thomsonreuters.com/data/environmental-social-governance/v1/views/measures-full'\n",
    "\n",
    "# access_token = 'uGR7cxvvqJ4mgWwva5pPN184iGGigBhY8g4ThFu0' # personal key for Data Science Accelerator access to ESG\n",
    "access_token = \"u5dfd3sUDp1tsQrrvEGvU6VXbl9ooVCc49Ry7Lmb\"\n",
    "\n",
    "def get_data_request(url, requestData):\n",
    "    '''HTTP GET request'''\n",
    "    dResp = requests.get(url, headers = {'X-api-key': access_token}, params = requestData);       \n",
    "\n",
    "    if dResp.status_code != 200:\n",
    "        raise ValueError(\"Unable to get data. Code %s, Message: %s\" % (dResp.status_code, dResp.text));\n",
    "    else:\n",
    "        print(\"Data access successful\")\n",
    "        jResp = json.loads(dResp.text);\n",
    "        return jResp\n",
    "\n",
    "def get_data(ric):\n",
    "    '''Gets ESG scores for a specific RIC (company) code'''\n",
    "    \n",
    "    requestData = {\n",
    "    \"universe\": ric\n",
    "    };\n",
    "\n",
    "    jResp = get_data_request(RESOURCE_ENDPOINT, requestData)\n",
    "\n",
    "    data = jResp[\"data\"]\n",
    "    headers = jResp[\"headers\"]    \n",
    "\n",
    "    names = [headers[x]['title'] for x in range(len(headers))]\n",
    "\n",
    "    df = pd.DataFrame(data, columns=names )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A csv file with all available Quandle end-of-day (EOD) data was read\n",
    "* This was used to check whether our ticker of interest is in the Quandl database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read available Quandl ticker symbols\n",
    "\n",
    "tickers = pd.read_csv('data/ticker_list.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* User-defined function: *aggregate*\n",
    "* This function pulls data for a single stock from Quandl, for a particular time period:\n",
    "    * We check if the stock of interest is in the Quandl database\n",
    "    * We calculate log returns (*log_ret* column)\n",
    "    * We create a *Date* column\n",
    "    * We create a *Year* column\n",
    "    * We group the data by year and calculate the mean stock price by year. This is needed to match stock price data with ESG Refinitiv data as the later are recorded yearly\n",
    "* We pull data from Refinitiv:\n",
    "    * We create a *Date* column\n",
    "    * We create a *Year* column\n",
    "    * We filter the data using the dates used to pull data from Quandl\n",
    "* We combine the Quandl and Refinitive data into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define essential loop function\n",
    "\n",
    "def aggregate(asset1, asset2, start_date=start, end_date=end):\n",
    "    \n",
    "    # Quandl\n",
    "    \n",
    "    if 'EOD/'+asset1.replace('.', '_') in list(tickers['Quandl_Code']):\n",
    "        \n",
    "        try:\n",
    "            quandl_data = quandl.get('EOD/'+asset1.replace('.', '_'), start_date=start_date, end_date=end_date)\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "        # Get stocks with at least X Quandl entries\n",
    "        \n",
    "        if len(quandl_data) >= 500:\n",
    "            quandl_data['log_ret'] = np.log(quandl_data.Adj_Close) - np.log(quandl_data.Adj_Close.shift(1))\n",
    "            quandl_data['Date'] = pd.to_datetime(quandl_data.index, format='%Y-%m-%d')\n",
    "            quandl_data['Year'] = quandl_data['Date'].dt.year\n",
    "            quandl_yearly = quandl_data.groupby(['Year']).mean()\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    # Refinitiv\n",
    "    \n",
    "    try:\n",
    "        refinitiv_data = get_data(asset2)\n",
    "    except:\n",
    "        return 0\n",
    "        \n",
    "    if len(refinitiv_data) != 0:\n",
    "        refinitiv_data['Date'] = pd.to_datetime(refinitiv_data['Period End Date'], format='%Y-%m-%d')\n",
    "        refinitiv_data['Year'] = refinitiv_data['Date'].dt.year\n",
    "        refinitiv_data['Period End Date'] = pd.to_datetime(refinitiv_data['Period End Date'], format='%Y-%m-%d')\n",
    "        refinitiv_data = refinitiv_data[(refinitiv_data['Period End Date'] >= start) & \n",
    "                                        (refinitiv_data['Period End Date'] <= end)]\n",
    "        refinitiv_data.set_index('Year', inplace=True)\n",
    "#         refinitiv_data.dropna(subset=['TRESG Combined Score'], inplace=True)\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "    # Join datasets (if both available)\n",
    "    \n",
    "    all_data = quandl_yearly.join(refinitiv_data, on='Year', how='left')\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quandl-Refinitiv loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We used a loop to iterate over 500 randomly chosen ticker symbols\n",
    "* We ran the *aggregate* function on those tickers that are found in the quandl database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 500\n",
    "\n",
    "index = random.sample(population=range(0, len(NASDAQ_quandl)), k=n)\n",
    "\n",
    "assets_quandl = [NASDAQ_quandl[i] for i in index]\n",
    "\n",
    "assets_ref = [NASDAQ_refinitiv[i] for i in index]\n",
    "\n",
    "datasets = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for asset1, asset2 in zip(assets_quandl,assets_ref):\n",
    "    \n",
    "    print(i, '/', n, ':', asset1, ',', asset2)\n",
    "    \n",
    "    data_tmp = aggregate(asset1, asset2)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if isinstance(data_tmp, pd.DataFrame):\n",
    "        datasets.append(data_tmp)\n",
    "        print(data_tmp.shape, '\\n')\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We get the common column names from all generated data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(datasets) >= 1:\n",
    "    \n",
    "    # Get all column names\n",
    "\n",
    "    col_names = []\n",
    "\n",
    "    for d in datasets:\n",
    "        col_names.append(d.columns)\n",
    "    \n",
    "    # Intersection of list of lists\n",
    "\n",
    "    unique_colnames = list(set.intersection(*map(set, col_names)))\n",
    "    \n",
    "else:\n",
    "    print('No datasets found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The loop-generated data frames are subsetted based on the common column names\n",
    "* This is necessary in order to be able to aggregate them all together\n",
    "* The processed data (i.e. *aggregate* function's outputs from the loop) are vertically stacked into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataframes in datasets\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for d in datasets:\n",
    "    df_tmp = d[np.intersect1d(d.columns, unique_colnames)]\n",
    "    df_tmp = df_tmp.loc[:, ~df_tmp.columns.duplicated()]\n",
    "    new_data.append(df_tmp)\n",
    "    \n",
    "# Merge dataframes in new_data list\n",
    "\n",
    "all_data = pd.concat(new_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the aggregated data into a csv file\n",
    "* Further analysis takes place in another jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('data/aggr_data_scores_500_alpha.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
